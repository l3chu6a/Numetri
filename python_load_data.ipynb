{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c3d15a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================\n",
    "# DATA HANDLING & ANALYSIS SCRIPT\n",
    "# Covers: Import, Cleaning, Validation, API/JSON/HTML Parsing\n",
    "# ===========================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sqlite3\n",
    "import requests\n",
    "import json\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# --- 1.1 Perform Standard Data Import, Joining and Aggregation Tasks ---\n",
    "# -------------------------------------------------------\n",
    "\n",
    "# 📥 Import data from flat files\n",
    "df_csv = pd.read_csv(\"data/sample.csv\")  # Replace with your actual path\n",
    "df_excel = pd.read_excel(\"data/sample.xlsx\")  # Requires openpyxl/xlrd\n",
    "\n",
    "# 🛢 Import data from SQLite database\n",
    "conn = sqlite3.connect(\"data/sample.db\")\n",
    "df_sql = pd.read_sql(\"SELECT * FROM employees\", conn)\n",
    "\n",
    "# 📊 Aggregate numeric, categorical variables, and dates\n",
    "df_grouped = df_csv.groupby(\"department\")[\"salary\"].mean().reset_index()\n",
    "\n",
    "# 🧩 Combine tables\n",
    "# Combine by rows (append)\n",
    "df_combined_rows = pd.concat([df_csv, df_excel], axis=0)\n",
    "\n",
    "# Combine by columns using key\n",
    "df_merged = pd.merge(df_csv, df_sql, on=\"employee_id\", how=\"inner\")\n",
    "\n",
    "# 🔍 Filter data based on multiple conditions\n",
    "filtered_df = df_csv[(df_csv[\"age\"] > 30) & (df_csv[\"department\"] == \"IT\")]\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# --- 1.2 Perform Cleaning Tasks ---\n",
    "# -------------------------------------------------------\n",
    "\n",
    "# 🔤 Match strings using regex: Names starting with 'A'\n",
    "df_filtered_names = df_csv[df_csv[\"name\"].str.contains(r\"^A\", regex=True)]\n",
    "\n",
    "# 🔁 Convert between types\n",
    "df_csv[\"date\"] = pd.to_datetime(df_csv[\"date\"], errors=\"coerce\")\n",
    "df_csv[\"age\"] = df_csv[\"age\"].astype(int, errors=\"ignore\")  # If clean\n",
    "\n",
    "# 🧼 Clean text: Trim and lowercase\n",
    "df_csv[\"department\"] = df_csv[\"department\"].str.strip().str.lower()\n",
    "\n",
    "# 🗓 Clean date/time: Extract year and month\n",
    "df_csv[\"year\"] = df_csv[\"date\"].dt.year\n",
    "df_csv[\"month\"] = df_csv[\"date\"].dt.month\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# --- 1.3 Assess Data Quality and Perform Validation Tasks ---\n",
    "# -------------------------------------------------------\n",
    "\n",
    "# ❓ Handle missing values: Fill null salaries with median\n",
    "df_csv[\"salary\"] = df_csv[\"salary\"].fillna(df_csv[\"salary\"].median())\n",
    "\n",
    "# ✅ Data validation\n",
    "# Duplicate check\n",
    "duplicates = df_csv[df_csv.duplicated(\"employee_id\")]\n",
    "\n",
    "# Value range check\n",
    "invalid_ages = df_csv[(df_csv[\"age\"] < 18) | (df_csv[\"age\"] > 65)]\n",
    "\n",
    "# 🆔 Validate data types\n",
    "print(\"Data types:\\n\", df_csv.dtypes)\n",
    "\n",
    "# Check if 'salary' column is numeric\n",
    "is_salary_numeric = pd.to_numeric(df_csv[\"salary\"], errors='coerce').notnull()\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# --- 1.4 Collect Data from Non-Standard Formats ---\n",
    "# -------------------------------------------------------\n",
    "\n",
    "# 🔧 Import JSON from API\n",
    "api_url = \"https://jsonplaceholder.typicode.com/users\"\n",
    "response = requests.get(api_url)\n",
    "data = response.json()\n",
    "df_api = pd.DataFrame(data)\n",
    "\n",
    "# 📂 Parse HTML with BeautifulSoup\n",
    "html = \"<html><body><h1>Title</h1><p class='content'>Hello World</p></body></html>\"\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "content = soup.find(\"p\", class_=\"content\").text  # Result: 'Hello World'\n",
    "\n",
    "# 📂 Parse raw JSON string\n",
    "json_str = '{\"name\": \"Alice\", \"age\": 25}'\n",
    "parsed_json = json.loads(json_str)\n",
    "\n",
    "# --- END OF SCRIPT ---\n",
    "print(\"✅ Script ran successfully. Review DataFrames for results.\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
